#Prototype_22041
#Humanised the output generated by the program for the end user, optimisation type identification
#New session for new lpp, prompting user for missing values

import streamlit as st
import google.generativeai as genai
from scipy.optimize import linprog
import os
import re

# --- Configure Google GenAI ---
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Google API key not found. Set it as an environment variable.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')


# --- Optimization Type Detection ---
OPT_TYPES = {
    "linear_programming": False,
    "integer_programming": False,
    "nonlinear_programming": False,
    "quadratic_programming": False,
    "convex_programming": False,
    "combinatorial_optimization": False,
    "dynamic_programming": False,
    "stochastic_optimization": False,
    "multi_objective_optimization": False
}

def detect_optimization_type(problem_statement):
    prompt = f"""
    You are an expert in optimization theory. Read the following problem statement and determine which types of optimization problems it involves.

    ---
    {problem_statement}
    ---

    Return a Python dictionary in the following format, setting only the relevant types to True:

    {OPT_TYPES}
    
    Respond ONLY with the dictionary. Do not include explanation.
    """
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    try:
        response = model.generate_content(prompt)
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0))
    except:
        pass
    return OPT_TYPES  # fallback

# --- Existing Functions (Preserved) ---
def humanize_response(technical_output):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are a formal mathematical assistant. The following is a technical explanation of a linear programming solution:

    ---
    {technical_output}
    ---

    Rewrite this in natural language to help a user understand what the solution means in simple terms. 
    Highlight the optimal value, key variables, and what they should take away from it. Be brief, helpful, and conversational.
    """

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"(‚ö†Ô∏è Could not generate humanized response: {e})\n\n{technical_output}"

import ast

def simplify_math_expressions(text):
    pattern = re.compile(r'\b(\d+(?:\.\d+)?)\s*\*\s*(\d+(?:\.\d+)?)\b')
    return pattern.sub(lambda m: str(float(m.group(1)) * float(m.group(2))), text)

def extract_lpp_from_text(text):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    
    prompt = f"""
    You are a world-class mathematical assistant designed to extract structured Linear Programming Problems (LPPs) from natural language.

    ---

    Your task involves **three stages**:

    ### üîÅ Stage 1: Unit Standardization
    1. Convert all quantities into **SI units**.
    2. **Reframe the problem text using SI units** for internal processing and validation.
    3. **Before final output**, convert all variables and constraints **back into their original units** as used in the question to avoid confusing the user.

    ---

    ### üß† Stage 2: LPP Extraction
    From the question below, extract the following LPP components:
    - Objective function coefficients for **both** `maximize` and `minimize` objectives:
      - If only one is mentioned, infer the other by negating or mirroring as needed.
    - Inequality constraints: matrix `A_ub`, vector `b_ub`, if any coefficient is absent for any constraint, clearly mark it inside the matrix as None and leave all the other floating values as they are.
    - Equality constraints: matrix `A_eq`, vector `b_eq` (or `None`), if any coefficient is absent for any constraint, clearly mark it inside the matrix as None and leave all the other floating values as they are
    - Variable bounds: list of `(lower, upper)` tuples. Default: `(0, None)` if not mentioned.
    - Variable names: e.g., `["x1", "x2", ...]` (generate meaningful names when possible).
    - Constraint names: e.g., `["Raw Material Constraint", "Budget Constraint", ...]`
    - Objective type: `"maximize"`, `"minimize"`, or `"mixed"`
    - missing: If there are any missing values in A_eq, b_eq, A_ub, b_ub or in the objective function, which should be marked as None within the matrices, this value is supposed to be set to True

    Ensure all values (coefficients, RHS, bounds) are floats and missing is boolean.

    ---

    ### üîÅ Stage 3: Matrix Verification (5-Pass Loop)
    Double-check the integrity of all matrices:
    - **Verify variable-to-column alignment**
    - **Ensure shape consistency** between `A_ub`, `b_ub`, `A_eq`, `b_eq`
    - **Confirm that all constraints, objective coefficients, and bounds reflect the original logic**
    - Repeat this validation logic **five times** before finalizing the dictionary to ensure consistency and correctness.

    ---

    ### üìù Input:
    \"\"\"{text}\"\"\"

    ---

    ### ‚úÖ Final Output Format
    Output ONLY a **valid Python dictionary** (no explanation, no markdown, no comments), strictly following this schema:

    {{
        "c_max": [float, ...] or [float, float or None, ...],
        "c_min": [float, ...] or [float, float or None, ...],
        "A_ub": [[float, ...], ...] or [[float, float or None, ...], ...],
        "b_ub": [float, ...] or [[float, float or None, ...], ...],
        "A_eq": [[float, ...], ...] or None or [[float, float or None, ...], ...],
        "b_eq": [float, ...] or None or [[float, float or None, ...], ...],
        "bounds": [(float, float or None), ...],
        "objective": "maximize" or "minimize" or "mixed",
        "variable_names": ["x1", "x2", ...],
        "constraint_names": ["Constraint 1", "Constraint 2", ...],
        "missing": True or False
    }}

    Return only the dictionary. Do not include code blocks, comments, or any other content.
    ---

    ### üö® Missing Values Handling
    If any value (such as `b_eq`, `A_eq`, or variable bounds) is inferred as `None`, include a placeholder and **clearly mark the corresponding variable or constraint name**.

    The downstream logic will prompt the user to optionally fill in the missing values. So do not guess ‚Äî just flag them with `None`.

    Only return the final LPP dictionary as described earlier.
    """

    response = model.generate_content(prompt)
    
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)

        if match:
            raw_dict = match.group(0)
            raw_dict = simplify_math_expressions(raw_dict)

            try:
                parsed_dict = ast.literal_eval(raw_dict)
            except Exception:
                parsed_dict = eval(raw_dict)

            st.session_state.history.append(("assistant", parsed_dict))
            return parsed_dict, None
        else:
            return None, "Invalid LPP format returned (no dictionary match)."
    
    except Exception as e:
        return None, f"‚ùå Error parsing LPP: {e}"


def solve_lpp(lpp_dict, alpha=0.5):
    c_max = lpp_dict.get('c_max')
    c_min = lpp_dict.get('c_min')
    A_ub = lpp_dict.get('A_ub')
    b_ub = lpp_dict.get('b_ub')
    A_eq = lpp_dict.get('A_eq')
    b_eq = lpp_dict.get('b_eq')
    bounds = lpp_dict.get('bounds')
    objective = lpp_dict.get('objective')

    num_vars = len(c_max) if c_max else len(c_min)
    if not bounds or len(bounds) != num_vars:
        bounds = [None for _ in range(num_vars)]

    if objective == 'maximize':
        c = [-val for val in c_max]
    elif objective == 'minimize':
        c = c_min
    elif objective == 'mixed':
        c = [(alpha * -x) + ((1 - alpha) * y) for x, y in zip(c_max, c_min)]
    else:
        return "Unknown objective type.", None, None

    try:
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            if objective == 'maximize':
                res.fun = -res.fun
            return None, res.fun, res.x
        else:
            return f"LPP solving failed: {res.message}", None, None
    except ValueError as e:
        return f"Error solving LPP: {e}", None, None

def display_constraints(lpp_dict):
    details = []
    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(lpp_dict.get('c_max', lpp_dict.get('c_min', []))))]    
    con_names = lpp_dict.get('constraint_names', [])

    if lpp_dict.get('A_ub'):
        for idx, (row, b) in enumerate(zip(lpp_dict['A_ub'], lpp_dict['b_ub'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[i]}" for i, coef in enumerate(row))
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} <= {b}")
    if lpp_dict.get('A_eq'):
        start_idx = len(lpp_dict.get('A_ub') or [])
        for i, (row, b) in enumerate(zip(lpp_dict['A_eq'], lpp_dict['b_eq'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[j]}" for j, coef in enumerate(row))
            idx = start_idx + i
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} = {b}")
    return "\n".join(details) or "No constraints found."

def format_solution(opt_val, opt_vars, objective, lpp_dict):
    if opt_val is None or opt_vars is None:
        return "No feasible solution found."

    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(opt_vars))]
    var_details = "\n".join([f"  - {name}: {val:.2f}" for name, val in zip(var_names, opt_vars)])

    summary = ""
    if objective == 'maximize' and lpp_dict.get('c_max'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_max'])]
        summary += "**Objective Function:** Maximize Z = " + " + ".join(terms) + "\n"
    elif objective == 'minimize' and lpp_dict.get('c_min'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_min'])]
        summary += "**Objective Function:** Minimize Z = " + " + ".join(terms) + "\n"
    elif objective == 'mixed':
        c_max = lpp_dict.get('c_max')
        c_min = lpp_dict.get('c_min')
        if c_max and c_min:
            terms = [f"(Œ±*-{x} + (1-Œ±)*{y})x{i+1}" for i, (x, y) in enumerate(zip(c_max, c_min))]
            summary += "**Objective Function:** Mixed = " + " + ".join(terms) + "\n"

    summary += "\n**Constraints:**\n" + display_constraints(lpp_dict) + "\n\n"
    result_text = f"Optimal Value: **{opt_val:.2f}**\n\nVariable Values:\n{var_details}"

    return summary + result_text






def modify_lpp(session_lpp, user_input):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are assisting in modifying a Linear Programming Problem (LPP). Here is the existing LPP in dictionary format:

    {session_lpp}

    Based on this user instruction:
    "{user_input}"

    Return an updated version of the dictionary **with only the necessary changes made**. 
    DO NOT remove or omit any fields from the original unless asked explicitly. Maintain structure integrity.

    Return ONLY the Python dictionary with changes implemented. No explanation or extra text.
    """
    response = model.generate_content(prompt)
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Failed to parse modified LPP."
    except Exception as e:
        return None, f"Error parsing modified LPP: {e}"




# LLM prompt generator (mocking GPT for now ‚Äî integrate your own model API here)
def generate_prompt(missing_type, variable_name=None, constraint_name=None):
    if missing_type == "A_eq":
        return model.generate_content(f"What is the coefficient of variable '{variable_name}' in constraint '{constraint_name}'?").text
    elif missing_type == "b_eq":
        return model.generate_content(f"What is the right-hand side value for constraint '{constraint_name}'?").text
    else:
        return model.generate_content(f"Please enter a value.").text


#########################################################################
#Issue####################################################################
#def ask_user_to_fill_missing_values(modified_lpp):
#    st.subheader("üõ† Help Complete the Optimization Problem")

#    updated = False
#    var_names = modified_lpp.get("variable_names", [])
#    con_names = modified_lpp.get("constraint_names", [])

    # Fill missing A_eq
#    if modified_lpp.get("A_eq") is None:
#        st.markdown("‚ûï **Missing equality constraint matrix (A_eq). Please fill in the coefficients.**")
#        num_vars = len(modified_lpp.get("c_max") or modified_lpp.get("c_min") or [])
#        num_eq = st.chat_input("How many equality constraints?")
#        modified_lpp["A_eq"] = []

#        for i in range(num_eq):
#            row = []
#            con_name = con_names[i] if i < len(con_names) else f"Constraint {i+1}"
#            for j in range(num_vars):
#                var_name = var_names[j] if j < len(var_names) else f"x{j+1}"
#                prompt = generate_prompt("A_eq", variable_name=var_name, constraint_name=con_name)
#                st.markdown(f"üìå **{prompt}**")
#                val = st.number_input(f"{con_name} - Coefficient for {var_name}", value=0.0, key=f"aeq_{i}_{j}")
#                row.append(val)
#            modified_lpp["A_eq"].append(row)
#        updated = True

    # Fill missing b_eq
#    if modified_lpp.get("b_eq") is None and modified_lpp.get("A_eq"):
#        st.markdown("‚û°Ô∏è **Missing RHS values (b_eq). Please provide the constants.**")
#        modified_lpp["b_eq"] = []
#        for i in range(len(modified_lpp["A_eq"])):
#            con_name = con_names[i] if i < len(con_names) else f"Constraint {i+1}"
#            prompt = generate_prompt("b_eq", constraint_name=con_name)
#            st.markdown(f"üßæ **{prompt}**")
#            val = st.number_input(f"RHS for {con_name}", value=0.0, key=f"beq_{i}")
#            modified_lpp["b_eq"].append(val)
#        updated = True

#    return modified_lpp if updated else None




# --- Streamlit App ---
st.set_page_config(page_title="LPP Optimizer Chat", layout="wide")
st.title("üî¢ Linear Programming Optimizer (Chat Interface)")
st.markdown("Describe your problem in natural language and let AI extract, solve, and refine it interactively.")

if 'history' not in st.session_state:
    st.session_state.history = []
if 'session_lpp' not in st.session_state:
    st.session_state.session_lpp = None

user_input = st.chat_input("Enter a new LPP description or a follow-up modification...")

if user_input:
    with st.spinner("Processing..."):
        lpp_data, error = extract_lpp_from_text(user_input)
        if st.session_state.session_lpp is None or not all(elem in lpp_data.get ("variable_names") for elem in st.session_state.session_lpp.get ("variable_names")):
            opt_types = detect_optimization_type(user_input)
            st.markdown ('New lpp detected')
    #        modified_lpp, error = extract_lpp_from_text(user_input)
            if error:
                st.session_state.history.append(("user", user_input))
                st.session_state.history.append(("assistant", f"‚ùå {error}"))
            else:
#                while lpp_data.get ("missing"):
#                    lpp_data = ask_user_to_fill_missing_values(lpp_data)

                err2, opt_val, opt_vars = solve_lpp(lpp_data)
                if err2:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                else:
                    formatted = format_solution(opt_val, opt_vars, lpp_data.get("objective"), lpp_data)
                    human_response = humanize_response(formatted)
                    st.session_state.session_lpp = lpp_data
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", human_response))
                    true_types = [key.replace("_", " ").title() for key, val in opt_types.items() if val]
                    if true_types:
                        st.session_state.history.append(("assistant", f"üìö **Detected Optimization Types:** `{', '.join(true_types)}`"))
                    else:
                        st.session_state.history.append(("assistant", "üìö **Detected Optimization Types:** `None detected`"))

        else:
            modified_lpp, error = modify_lpp(st.session_state.session_lpp, user_input)
            if error:
                st.session_state.history.append(("user", user_input))
                st.session_state.history.append(("assistant", f"‚ùå {error}"))
            else:
#####################
                # Check if any missing values need to be filled
                if modified_lpp:
#                    if modified_lpp.get ("missing"):
#                        modified_lpp = ask_user_to_fill_missing_values(modified_lpp)

 #                   else:
#                if modified_lpp:  # If there are updates, solve the LPP
                        err2, opt_val, opt_vars = solve_lpp(modified_lpp)
                        err2, opt_val, opt_vars = solve_lpp(modified_lpp)
                        if err2:
                            st.session_state.history.append(("user", user_input))
                            st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                        else:
                            formatted = format_solution(opt_val, opt_vars, modified_lpp.get("objective"), modified_lpp)
                            human_response = humanize_response(formatted)
                            st.session_state.session_lpp = modified_lpp
                            st.session_state.history.append(("user", user_input))
                            st.session_state.history.append(("assistant", human_response))

# --- Chat Display ---
for sender, message in st.session_state.history:
    with st.chat_message(sender):
        st.markdown(message)
