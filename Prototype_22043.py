#Prototype_22041
#Humanised the output generated by the program for the end user, optimisation type identification
#New session for new lpp, prompting user for missing values
#Linear and non-linear with follow-ups

import streamlit as st
import google.generativeai as genai
from scipy.optimize import linprog, minimize
import os
import re

# --- Configure Google GenAI ---
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Google API key not found. Set it as an environment variable.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')


# --- Optimization Type Detection ---
OPT_TYPES = {
    "linear_programming": False,
    "integer_programming": False,
    "nonlinear_programming": False,
    "quadratic_programming": False,
    "convex_programming": False,
    "combinatorial_optimization": False,
    "dynamic_programming": False,
    "stochastic_optimization": False,
    "multi_objective_optimization": False
}

def detect_optimization_type(problem_statement):
    prompt = f"""
    You are an expert in optimization theory. Read the following problem statement and determine which types of optimization problems it involves.

    ---
    {problem_statement}
    ---

    Return a Python dictionary in the following format, setting only the relevant types to True:

    {OPT_TYPES}
    
    Respond ONLY with the dictionary. Do not include explanation.
    """
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    try:
        response = model.generate_content(prompt)
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0))
    except:
        pass
    return OPT_TYPES  # fallback

# --- Existing Functions (Preserved) ---
def humanize_response(technical_output, problem_type="optimization"):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are a formal mathematical assistant. The following is a technical explanation of a {problem_type} solution:

    ---
    {technical_output}
    ---

    Rewrite this in natural language to help a user understand what the solution means in simple terms.
    Highlight the optimal value, key variables, and what they should take away from it. Be brief, helpful, and conversational.
    """

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"(‚ö†Ô∏è Could not generate humanized response: {e})\n\n{technical_output}"

import ast

def simplify_math_expressions(text):
    pattern = re.compile(r'\b(\d+(?:\.\d+)?)\s*\*\s*(\d+(?:\.\d+)?)\b')
    return pattern.sub(lambda m: str(float(m.group(1)) * float(m.group(2))), text)

def extract_lpp_from_text(text):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    
    prompt = f"""
    You are a world-class mathematical assistant designed to extract structured Linear Programming Problems (LPPs) from natural language.

    ---

    Your task involves **three stages**:

    ### üîÅ Stage 1: Unit Standardization
    1. Convert all quantities into **SI units**.
    2. **Reframe the problem text using SI units** for internal processing and validation.
    3. **Before final output**, convert all variables and constraints **back into their original units** as used in the question to avoid confusing the user.

    ---

    ### üß† Stage 2: LPP Extraction
    From the question below, extract the following LPP components:
    - Objective function coefficients for **both** `maximize` and `minimize` objectives:
      - If only one is mentioned, infer the other by negating or mirroring as needed.
    - Inequality constraints: matrix `A_ub`, vector `b_ub`
    - Equality constraints: matrix `A_eq`, vector `b_eq`
    - Variable bounds: list of `(lower, upper)` tuples. Default: `(0, None)` if not mentioned.
    - Variable names: e.g., `["x1", "x2", ...]` (generate meaningful names when possible).
    - Constraint names: e.g., `["Raw Material Constraint", "Budget Constraint", ...]`
    - Objective type: `"maximize"`, `"minimize"`, or `"mixed"`
    Ensure all values (coefficients, RHS, bounds) are floats.

    ---

    ### üîÅ Stage 3: Matrix Verification (5-Pass Loop)
    Double-check the integrity of all matrices:
    - **Verify variable-to-column alignment**
    - **Ensure shape consistency** between `A_ub`, `b_ub`, `A_eq`, `b_eq`
    - **Confirm that all constraints, objective coefficients, and bounds reflect the original logic**
    - Repeat this validation logic **five times** before finalizing the dictionary to ensure consistency and correctness.

    ---

    ### üìù Input:
    \"\"\"{text}\"\"\"

    ---

    ### ‚úÖ Final Output Format
    Output ONLY a **valid Python dictionary** (no explanation, no markdown, no comments), strictly following this schema:

    {{
        "c_max": [float, ...],
        "c_min": [float, ...],
        "A_ub": [[float, ...], ...],
        "b_ub": [float, ...],
        "A_eq": [[float, ...], ...] or None,
        "b_eq": [float, ...] or None,
        "bounds": [(float, float or None), ...],
        "objective": "maximize" or "minimize" or "mixed",
        "variable_names": ["x1", "x2", ...],
        "constraint_names": ["Constraint 1", "Constraint 2", ...]
    }}

    Return only the dictionary. Do not include code blocks, comments, or any other content.
    ---

    ### üö® Missing Values Handling
    If any value (such as `b_eq`, `A_eq`, or variable bounds) is inferred as `None`, include a placeholder and **clearly mark the corresponding variable or constraint name**.

    The downstream logic will prompt the user to optionally fill in the missing values. So do not guess ‚Äî just flag them with `None`.

    Only return the final LPP dictionary as described earlier.
    """

    response = model.generate_content(prompt)
    
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)

        if match:
            raw_dict = match.group(0)
            raw_dict = simplify_math_expressions(raw_dict)

            try:
                parsed_dict = ast.literal_eval(raw_dict)
            except Exception:
                parsed_dict = eval(raw_dict)

            st.session_state.history.append(("assistant", parsed_dict))
            return parsed_dict, None
        else:
            return None, "Invalid LPP format returned (no dictionary match)."
    
    except Exception as e:
        return None, f"‚ùå Error parsing LPP: {e}"


def solve_lpp(lpp_dict, alpha=0.5):
    c_max = lpp_dict.get('c_max')
    c_min = lpp_dict.get('c_min')
    A_ub = lpp_dict.get('A_ub')
    b_ub = lpp_dict.get('b_ub')
    A_eq = lpp_dict.get('A_eq')
    b_eq = lpp_dict.get('b_eq')
    bounds = lpp_dict.get('bounds')
    objective = lpp_dict.get('objective')

    num_vars = len(c_max) if c_max else len(c_min)
    if not bounds or len(bounds) != num_vars:
        bounds = [None for _ in range(num_vars)]

    if objective == 'maximize':
        c = [-val for val in c_max]
    elif objective == 'minimize':
        c = c_min
    elif objective == 'mixed':
        c = [(alpha * -x) + ((1 - alpha) * y) for x, y in zip(c_max, c_min)]
    else:
        return "Unknown objective type.", None, None

    try:
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            if objective == 'maximize':
                res.fun = -res.fun
            return None, res.fun, res.x
        else:
            return f"LPP solving failed: {res.message}", None, None
    except ValueError as e:
        return f"Error solving LPP: {e}", None, None

def display_constraints(lpp_dict):
    details = []
    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(lpp_dict.get('c_max', lpp_dict.get('c_min', []))))]    
    con_names = lpp_dict.get('constraint_names', [])

    if lpp_dict.get('A_ub'):
        for idx, (row, b) in enumerate(zip(lpp_dict['A_ub'], lpp_dict['b_ub'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[i]}" for i, coef in enumerate(row))
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} <= {b}")
    if lpp_dict.get('A_eq'):
        start_idx = len(lpp_dict.get('A_ub') or [])
        for i, (row, b) in enumerate(zip(lpp_dict['A_eq'], lpp_dict['b_eq'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[j]}" for j, coef in enumerate(row))
            idx = start_idx + i
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} = {b}")
    return "\n".join(details) or "No constraints found."

def format_solution(opt_val, opt_vars, objective, lpp_dict):
    if opt_val is None or opt_vars is None:
        return "No feasible solution found."

    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(opt_vars))]
    var_details = "\n".join([f"  - {name}: {val:.2f}" for name, val in zip(var_names, opt_vars)])

    summary = ""
    if objective == 'maximize' and lpp_dict.get('c_max'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_max'])]
        summary += "**Objective Function:** Maximize Z = " + " + ".join(terms) + "\n"
    elif objective == 'minimize' and lpp_dict.get('c_min'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_min'])]
        summary += "**Objective Function:** Minimize Z = " + " + ".join(terms) + "\n"
    elif objective == 'mixed':
        c_max = lpp_dict.get('c_max')
        c_min = lpp_dict.get('c_min')
        if c_max and c_min:
            terms = [f"(Œ±*-{x} + (1-Œ±)*{y})x{i+1}" for i, (x, y) in enumerate(zip(c_max, c_min))]
            summary += "**Objective Function:** Mixed = " + " + ".join(terms) + "\n"

    summary += "\n**Constraints:**\n" + display_constraints(lpp_dict) + "\n\n"
    result_text = f"Optimal Value: **{opt_val:.2f}**\n\nVariable Values:\n{var_details}"

    return summary + result_text






def modify_lpp(session_lpp, user_input):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are assisting in modifying a Linear Programming Problem (LPP). Here is the existing LPP in dictionary format:

    {session_lpp}

    Based on this user instruction:
    "{user_input}"

    Return an updated version of the dictionary **with only the necessary changes made**. 
    DO NOT remove or omit any fields from the original unless asked explicitly. Maintain structure integrity.

    Return ONLY the Python dictionary with changes implemented. No explanation or extra text.
    """
    response = model.generate_content(prompt)
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Failed to parse modified LPP."
    except Exception as e:
        return None, f"Error parsing modified LPP: {e}"




# LLM prompt generator (mocking GPT for now ‚Äî integrate your own model API here)
def generate_prompt(missing_type, variable_name=None, constraint_name=None):
    if missing_type == "A_eq":
        return model.generate_content(f"What is the coefficient of variable '{variable_name}' in constraint '{constraint_name}'?").text
    elif missing_type == "b_eq":
        return model.generate_content(f"What is the right-hand side value for constraint '{constraint_name}'?").text
    else:
        return model.generate_content(f"Please enter a value.").text


#########################################################################
#Issue####################################################################
#def ask_user_to_fill_missing_values(modified_lpp):
#    st.subheader("üõ† Help Complete the Optimization Problem")

#    updated = False
#    var_names = modified_lpp.get("variable_names", [])
#    con_names = modified_lpp.get("constraint_names", [])

    # Fill missing A_eq
#    if modified_lpp.get("A_eq") is None:
#        st.markdown("‚ûï **Missing equality constraint matrix (A_eq). Please fill in the coefficients.**")
#        num_vars = len(modified_lpp.get("c_max") or modified_lpp.get("c_min") or [])
#        num_eq = st.chat_input("How many equality constraints?")
#        modified_lpp["A_eq"] = []

#        for i in range(num_eq):
#            row = []
#            con_name = con_names[i] if i < len(con_names) else f"Constraint {i+1}"
#            for j in range(num_vars):
#                var_name = var_names[j] if j < len(var_names) else f"x{j+1}"
#                prompt = generate_prompt("A_eq", variable_name=var_name, constraint_name=con_name)
#                st.markdown(f"üìå **{prompt}**")
#                val = st.number_input(f"{con_name} - Coefficient for {var_name}", value=0.0, key=f"aeq_{i}_{j}")
#                row.append(val)
#            modified_lpp["A_eq"].append(row)
#        updated = True

    # Fill missing b_eq
#    if modified_lpp.get("b_eq") is None and modified_lpp.get("A_eq"):
#        st.markdown("‚û°Ô∏è **Missing RHS values (b_eq). Please provide the constants.**")
#        modified_lpp["b_eq"] = []
#        for i in range(len(modified_lpp["A_eq"])):
#            con_name = con_names[i] if i < len(con_names) else f"Constraint {i+1}"
#            prompt = generate_prompt("b_eq", constraint_name=con_name)
#            st.markdown(f"üßæ **{prompt}**")
#            val = st.number_input(f"RHS for {con_name}", value=0.0, key=f"beq_{i}")
#            modified_lpp["b_eq"].append(val)
#        updated = True

#    return modified_lpp if updated else None



# --- Non-Linear Programming Functions ---
def extract_nlp_components(problem_statement):
    prompt = f"""
    You are an expert in extracting components of a Non-Linear Programming (NLP) problem from natural language.

    ---
    From the following problem statement, identify and extract:

    - **Objective Function (as a Python string representing a lambda function with variables 'x[0]', 'x[1]', ...):** Express the function to be minimized or maximized.
    - **Objective Type:** "minimize" or "maximize".
    - **Constraints (a list of dictionaries, each with 'type' ('eq' or 'ineq') and 'fun' (as a Python string representing a lambda function with 'x')):** Represent the equality and inequality constraints.
    - **Initial Guess (a list of initial values for the variables):** Provide a reasonable starting point for the optimization.
    - **Variable Names (a list of names for the variables):**
    - **Constraint Descriptions (a list of human-readable descriptions for the constraints):**

    If any component cannot be reliably extracted, indicate with None.

    For the given problem:
    "Nestl√© produces two types of chocolates‚ÄîMilk Chocolate and Dark Chocolate‚Äîand wants to maximize its profit while considering non-linear production costs. The selling price per unit is ‚Çπ200 for Milk Chocolate and ‚Çπ250 for Dark Chocolate. However, the cost per unit follows a non-linear pattern: ‚Çπ(50 + 0.01M¬≤) for Milk Chocolate and ‚Çπ(70 + 0.008D¬≤) for Dark Chocolate. The company has 10,000 kg of cocoa, with each Milk Chocolate requiring 3 kg and each Dark Chocolate needing 5 kg. The goal is to determine the optimal number of chocolates to produce while ensuring total cocoa usage does not exceed the limit."

    A potential output structure would be (adjust variable names and function definitions based on your interpretation):

    {{
        "objective_function": "lambda x: (200 * x[0]) + (250 * x[1]) - (50 + 0.01 * x[0]**2) - (70 + 0.008 * x[1]**2)",
        "objective_type": "maximize",
        "constraints": [
            {{'type': 'ineq', 'fun': "lambda x: 10000 - (3 * x[0] + 5 * x[1])" }}
        ],
        "initial_guess": [100, 100],
        "variable_names": ["Milk Chocolate", "Dark Chocolate"],
        "constraint_descriptions": ["Total cocoa usage within limit"]
    }}

    ---
    Problem Statement:
    \"\"\"{problem_statement}\"\"\"

    ---
    Return ONLY a Python dictionary in the specified format. Ensure that 'objective_function' and the 'fun' part of 'constraints' are strings representing lambda functions. Do not include any explanation or extra text.
    """
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    try:
        response = model.generate_content(prompt)
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Invalid NLP format returned."
    except Exception as e:
        return None, f"Error parsing NLP: {e}"


def solve_nlp(nlp_dict):
    objective_func_str = nlp_dict.get('objective_function')
    objective_type = nlp_dict.get('objective_type', 'minimize')
    constraints_data = nlp_dict.get('constraints', [])
    initial_guess = nlp_dict.get('initial_guess')

    if not objective_func_str or not initial_guess:
        return "Objective function or initial guess not provided.", None, None

    try:
        objective_function = eval(objective_func_str)
    except Exception as e:
        return f"Error evaluating objective function: {e}", None, None

    formatted_constraints = []
    if constraints_data:
        for con in constraints_data:
            try:
                func = eval(con['fun'])
                formatted_constraints.append({'type': con['type'], 'fun': func})
            except Exception as e:
                return f"Error evaluating constraint: {e}", None, None

    if objective_type == 'maximize':
        def negative_objective(x):
            return -objective_function(x)
        solver_objective = negative_objective
    else:
        solver_objective = objective_function

    try:
        result = minimize(solver_objective, initial_guess, constraints=formatted_constraints, method='SLSQP')
        if result.success:
            optimal_value = result.fun if objective_type == 'minimize' else -result.fun
            return None, optimal_value, result.x
        else:
            return f"NLP solving failed: {result.message}", None, None
    except Exception as e:
        return f"Error solving NLP: {e}", None, None

def format_nlp_solution(opt_val, opt_vars, objective, nlp_dict):
    if opt_val is None or opt_vars is None:
        return "No feasible solution found."

    var_names = nlp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(opt_vars))]
    var_details = "\n".join([f"  - {name}: {val:.4f}" for name, val in zip(var_names, opt_vars)])
    objective_str = nlp_dict.get('objective_function_original', "Objective Function") # Consider storing original string

    summary = f"**Objective Function:** {objective_str} ({objective})\n\n"
    if nlp_dict.get('constraint_descriptions'):
        summary += "**Constraints:**\n" + "\n".join([f"- {desc}" for desc in nlp_dict['constraint_descriptions']]) + "\n\n"

    result_text = f"Optimal Value: **{opt_val:.4f}**\n\nVariable Values:\n{var_details}"
    return summary + result_text

def modify_nlp(session_nlp, user_input):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are assisting in modifying a Non-Linear Programming (NLP) problem. Here is the existing NLP in dictionary format:

    {session_nlp}

    Based on this user instruction:
    "{user_input}"

    Return an updated version of the dictionary **with only the necessary changes made**.
    Ensure that the 'objective_function' and constraint 'fun' values remain as Python-executable strings (lambda functions).
    DO NOT remove or omit any fields from the original unless asked explicitly. Maintain structure integrity.

    Return ONLY the Python dictionary with changes implemented. No explanation or extra text.
    """
    response = model.generate_content(prompt)
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Failed to parse modified NLP."
    except Exception as e:
        return None, f"Error parsing modified NLP: {e}"


def classify_user_input(user_input, session_lpp=None):
    prompt = f"""
    You are an intelligent assistant that classifies user instructions in the context of optimization problems.

    Given the following current problem description (if any):
    \"\"\"{session_lpp or 'None'}\"\"\"

    And the user's latest input:
    \"\"\"{user_input}\"\"\"

    Decide whether the user's input is:
    - A completely **new optimization problem**, or
    - A **modification or follow-up** to the existing one.

    Return only one word as a response:
    "new" ‚Üí if it's a new problem
    "followup" ‚Üí if it's related to the existing one
    """

    try:
        response = model.generate_content(prompt)
        answer = response.text.strip().lower()
        if "new" in answer:
            return None
        elif "followup" in answer:
            return st.session_state.session_lpp
        else:
            return "unknown"
    except Exception as e:
        return f"error: {e}"




# --- Streamlit App ---
st.set_page_config(page_title="LPP Optimizer Chat", layout="wide")
st.title("üî¢ Linear Programming Optimizer (Chat Interface)")
st.markdown("Describe your problem in natural language and let AI extract, solve, and refine it interactively.")

if 'history' not in st.session_state:
    st.session_state.history = []
if 'session_lpp' not in st.session_state:
    st.session_state.session_lpp = None
if 'session_problem' not in st.session_state:
    st.session_state.session_problem = None  # Initialize problem_type


user_input = st.chat_input("Enter a new LPP description or a follow-up modification...")

if user_input:
    st.session_state.session_lpp = classify_user_input(user_input, st.session_state.session_lpp)
    with st.spinner("Processing..."):
      if st.session_state.session_lpp is None:
        opt_types = detect_optimization_type(user_input)
        if opt_types.get("linear_programming", False):
          st.session_state.session_problem = "linear"
          lpp_data, error = extract_lpp_from_text(user_input)
    #    if st.session_state.session_lpp is None:

# or not all(elem in lpp_data.get ("variable_names") for elem in st.session_state.session_lpp.get ("variable_names")):
          st.markdown ('New lpp detected')
    #        modified_lpp, error = extract_lpp_from_text(user_input)
          if error:
                st.session_state.history.append(("user", user_input))
                st.session_state.history.append(("assistant", f"‚ùå {error}"))
          else:
#                while lpp_data.get ("missing"):
#                    lpp_data = ask_user_to_fill_missing_values(lpp_data)

                err2, opt_val, opt_vars = solve_lpp(lpp_data)
                if err2:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                else:
                    formatted = format_solution(opt_val, opt_vars, lpp_data.get("objective"), lpp_data)
                    human_response = humanize_response(formatted)
                    st.session_state.session_lpp = lpp_data
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", human_response))
                    true_types = [key.replace("_", " ").title() for key, val in opt_types.items() if val]
                    if true_types:
                        st.session_state.history.append(("assistant", f"üìö **Detected Optimization Types:** `{', '.join(true_types)}`"))
                    else:
                        st.session_state.history.append(("assistant", "üìö **Detected Optimization Types:** `None detected`"))


        elif opt_types.get("nonlinear_programming", False):
                st.session_state.session_problem = "nonlinear"
                nlp_data, error = extract_nlp_components(user_input)
                if error:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {error}"))
                else:
                    err2, opt_val, opt_vars = solve_nlp(nlp_data)
                    if err2:
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                    else:
                        # Store the original objective function string for better output
                        nlp_data['objective_function_original'] = re.search(r"lambda x: (.+)", nlp_data.get('objective_function', ''))[1] if nlp_data.get('objective_function') else "Objective Function"
                        formatted = format_nlp_solution(opt_val, opt_vars, nlp_data.get("objective_type", "minimize"), nlp_data)
                        human_response = humanize_response(formatted, "non-linear programming")
                        st.session_state.session_lpp = nlp_data
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", human_response))
                        true_types = [key.replace("_", " ").title() for key, val in opt_types.items() if val]
                        if true_types:
                            st.session_state.history.append(("assistant", f"üìö **Detected Optimization Types:** {', '.join(true_types)}"))
                        else:
                            st.session_state.history.append(("assistant", "üìö **Detected Optimization Types:** None detected"))



##################################
      else:
            if st.session_state.session_problem == "linear":
                modified_lpp, error = modify_lpp(st.session_state.session_lpp, user_input)
                if error:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {error}"))
                else:
                    err2, opt_val, opt_vars = solve_lpp(modified_lpp)
                    if err2:
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                    else:
                        formatted = format_solution(opt_val, opt_vars, modified_lpp.get("objective"), modified_lpp)
                        human_response = humanize_response(formatted, "linear programming")
                        st.session_state.session_lpp = modified_lpp
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", human_response))
            elif st.session_state.session_problem == "nonlinear":
                modified_nlp, error = modify_nlp(st.session_state.session_lpp, user_input)
                if error:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {error}"))
                else:
                    err2, opt_val, opt_vars = solve_nlp(modified_nlp)
                    if err2:
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                    else:
                        formatted = format_nlp_solution(opt_val, opt_vars, modified_nlp.get("objective_type", "minimize"), modified_nlp)
                        human_response = humanize_response(formatted, "non-linear programming")
                        st.session_state.session_lpp = modified_nlp
                        st.session_state.history.append(("user", user_input))
                        st.session_state.history.append(("assistant", human_response))



# --- Chat Display ---
for sender, message in st.session_state.history:
    with st.chat_message(sender):
        st.markdown(message)

