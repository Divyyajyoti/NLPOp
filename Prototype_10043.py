#Prototype_10043.py
#Humanised the output generated by the program for the end user, optimisation type identification

import streamlit as st
import google.generativeai as genai
from scipy.optimize import linprog
import os
import re

# --- Configure Google GenAI ---
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Google API key not found. Set it as an environment variable.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

# --- Optimization Type Detection ---
OPT_TYPES = {
    "linear_programming": False,
    "integer_programming": False,
    "nonlinear_programming": False,
    "quadratic_programming": False,
    "convex_programming": False,
    "combinatorial_optimization": False,
    "dynamic_programming": False,
    "stochastic_optimization": False,
    "multi_objective_optimization": False
}

def detect_optimization_type(problem_statement):
    prompt = f"""
    You are an expert in optimization theory. Read the following problem statement and determine which types of optimization problems it involves.

    ---
    {problem_statement}
    ---

    Return a Python dictionary in the following format, setting only the relevant types to True:

    {OPT_TYPES}
    
    Respond ONLY with the dictionary. Do not include explanation.
    """
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    try:
        response = model.generate_content(prompt)
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0))
    except:
        pass
    return OPT_TYPES  # fallback

# --- Existing Functions (Preserved) ---
def humanize_response(technical_output):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are a formal mathematical assistant. The following is a technical explanation of a linear programming solution:

    ---
    {technical_output}
    ---

    Rewrite this in natural language to help a user understand what the solution means in simple terms. 
    Highlight the optimal value, key variables, and what they should take away from it. Be brief, helpful, and conversational.
    """

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"(‚ö†Ô∏è Could not generate humanized response: {e})\n\n{technical_output}"

def extract_lpp_from_text(text):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are a world-class mathematical assistant designed to extract structured Linear Programming Problems (LPPs) from natural language.

    ---

    Your task involves **three stages**:

    ### üîÅ Stage 1: Unit Standardization
    1. Convert all quantities into **SI units**.
    2. **Reframe the problem text using SI units** for internal processing and validation.
    3. **Before final output**, convert all variables and constraints **back into their original units** as used in the question to avoid confusing the user.

    ---

    ### üß† Stage 2: LPP Extraction
    From the question below, extract the following LPP components:
    - Objective function coefficients for **both** `maximize` and `minimize` objectives:
      - If only one is mentioned, infer the other by negating or mirroring as needed.
    - Inequality constraints: matrix `A_ub`, vector `b_ub`
    - Equality constraints: matrix `A_eq`, vector `b_eq` (or `None`)
    - Variable bounds: list of `(lower, upper)` tuples. Default: `(0, None)` if not mentioned.
    - Variable names: e.g., `["x1", "x2", ...]` (generate meaningful names when possible).
    - Constraint names: e.g., `["Raw Material Constraint", "Budget Constraint", ...]`
    - Objective type: `"maximize"`, `"minimize"`, or `"mixed"`

    Ensure all values (coefficients, RHS, bounds) are floats.

    ---

    ### üîÅ Stage 3: Matrix Verification (5-Pass Loop)
    Double-check the integrity of all matrices:
    - **Verify variable-to-column alignment**
    - **Ensure shape consistency** between `A_ub`, `b_ub`, `A_eq`, `b_eq`
    - **Confirm that all constraints, objective coefficients, and bounds reflect the original logic**
    - Repeat this validation logic **five times** before finalizing the dictionary to ensure consistency and correctness.

    ---

    ### üìù Input:
    \"\"\"{text}\"\"\"

    ---

    ### ‚úÖ Final Output Format
    Output ONLY a **valid Python dictionary** (no explanation, no markdown, no comments), strictly following this schema:

    {{
        "c_max": [float, ...],
        "c_min": [float, ...],
        "A_ub": [[float, ...], ...],
        "b_ub": [float, ...],
        "A_eq": [[float, ...], ...] or None,
        "b_eq": [float, ...] or None,
        "bounds": [(float, float or None), ...],
        "objective": "maximize" or "minimize" or "mixed",
        "variable_names": ["x1", "x2", ...],
        "constraint_names": ["Constraint 1", "Constraint 2", ...]
    }}

    Return only the dictionary. Do not include code blocks, comments, or any other content.
    ---

    ### üö® Missing Values Handling
    If any value (such as `b_eq`, `A_eq`, or variable bounds) is inferred as `None`, include a placeholder and **clearly mark the corresponding variable or constraint name**.

    The downstream logic will prompt the user to optionally fill in the missing values. So do not guess ‚Äî just flag them with `None`.

    Return the output dictionary with `None` where applicable and let the app handle user follow-up.

    Only return the final LPP dictionary as described earlier.

    """
    response = model.generate_content(prompt)
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Invalid LPP format returned."
    except Exception as e:
        return None, f"Error parsing LPP: {e}"

def solve_lpp(lpp_dict, alpha=0.5):
    c_max = lpp_dict.get('c_max')
    c_min = lpp_dict.get('c_min')
    A_ub = lpp_dict.get('A_ub')
    b_ub = lpp_dict.get('b_ub')
    A_eq = lpp_dict.get('A_eq')
    b_eq = lpp_dict.get('b_eq')
    bounds = lpp_dict.get('bounds')
    objective = lpp_dict.get('objective')

    num_vars = len(c_max) if c_max else len(c_min)
    if not bounds or len(bounds) != num_vars:
        bounds = [(0, None) for _ in range(num_vars)]

    if objective == 'maximize':
        c = [-val for val in c_max]
    elif objective == 'minimize':
        c = c_min
    elif objective == 'mixed':
        c = [(alpha * -x) + ((1 - alpha) * y) for x, y in zip(c_max, c_min)]
    else:
        return "Unknown objective type.", None, None

    try:
        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')
        if res.success:
            if objective == 'maximize':
                res.fun = -res.fun
            return None, res.fun, res.x
        else:
            return f"LPP solving failed: {res.message}", None, None
    except ValueError as e:
        return f"Error solving LPP: {e}", None, None

def display_constraints(lpp_dict):
    details = []
    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(lpp_dict.get('c_max', lpp_dict.get('c_min', []))))]    
    con_names = lpp_dict.get('constraint_names', [])

    if lpp_dict.get('A_ub'):
        for idx, (row, b) in enumerate(zip(lpp_dict['A_ub'], lpp_dict['b_ub'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[i]}" for i, coef in enumerate(row))
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} <= {b}")
    if lpp_dict.get('A_eq'):
        start_idx = len(lpp_dict.get('A_ub') or [])
        for i, (row, b) in enumerate(zip(lpp_dict['A_eq'], lpp_dict['b_eq'])):
            constraint = " + ".join(f"{round(coef, 2)}{var_names[j]}" for j, coef in enumerate(row))
            idx = start_idx + i
            name = con_names[idx] if idx < len(con_names) else f"Constraint {idx+1}"
            details.append(f"{name}: {constraint} = {b}")
    return "\n".join(details) or "No constraints found."

def format_solution(opt_val, opt_vars, objective, lpp_dict):
    if opt_val is None or opt_vars is None:
        return "No feasible solution found."

    var_names = lpp_dict.get('variable_names') or [f"x{i+1}" for i in range(len(opt_vars))]
    var_details = "\n".join([f"  - {name}: {val:.2f}" for name, val in zip(var_names, opt_vars)])

    summary = ""
    if objective == 'maximize' and lpp_dict.get('c_max'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_max'])]
        summary += "**Objective Function:** Maximize Z = " + " + ".join(terms) + "\n"
    elif objective == 'minimize' and lpp_dict.get('c_min'):
        terms = [f"{round(coef, 2)}x{i+1}" for i, coef in enumerate(lpp_dict['c_min'])]
        summary += "**Objective Function:** Minimize Z = " + " + ".join(terms) + "\n"
    elif objective == 'mixed':
        c_max = lpp_dict.get('c_max')
        c_min = lpp_dict.get('c_min')
        if c_max and c_min:
            terms = [f"(Œ±*-{x} + (1-Œ±)*{y})x{i+1}" for i, (x, y) in enumerate(zip(c_max, c_min))]
            summary += "**Objective Function:** Mixed = " + " + ".join(terms) + "\n"

    summary += "\n**Constraints:**\n" + display_constraints(lpp_dict) + "\n\n"
    result_text = f"Optimal Value: **{opt_val:.2f}**\n\nVariable Values:\n{var_details}"

    return summary + result_text






def modify_lpp(session_lpp, user_input):
    model = genai.GenerativeModel('models/learnlm-1.5-pro-experimental')
    prompt = f"""
    You are assisting in modifying a Linear Programming Problem (LPP). Here is the existing LPP in dictionary format:

    {session_lpp}

    Based on this user instruction:
    "{user_input}"

    Return an updated version of the dictionary **with only the necessary changes made**. 
    DO NOT remove or omit any fields from the original unless asked explicitly. Maintain structure integrity.

    Return ONLY the Python dictionary with changes implemented. No explanation or extra text.
    """
    response = model.generate_content(prompt)
    try:
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return eval(match.group(0)), None
        else:
            return None, "Failed to parse modified LPP."
    except Exception as e:
        return None, f"Error parsing modified LPP: {e}"

# --- Streamlit App ---
st.set_page_config(page_title="LPP Optimizer Chat", layout="wide")
st.title("üî¢ Linear Programming Optimizer (Chat Interface)")
st.markdown("Describe your problem in natural language and let AI extract, solve, and refine it interactively.")

if 'history' not in st.session_state:
    st.session_state.history = []
if 'session_lpp' not in st.session_state:
    st.session_state.session_lpp = None

user_input = st.chat_input("Enter a new LPP description or a follow-up modification...")

if user_input:
    with st.spinner("Processing..."):
        if st.session_state.session_lpp is None:
            opt_types = detect_optimization_type(user_input)
            lpp_data, error = extract_lpp_from_text(user_input)
            if error:
                st.session_state.history.append(("user", user_input))
                st.session_state.history.append(("assistant", f"‚ùå {error}"))
            else:
                err2, opt_val, opt_vars = solve_lpp(lpp_data)
                if err2:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                else:
                    formatted = format_solution(opt_val, opt_vars, lpp_data.get("objective"), lpp_data)
                    human_response = humanize_response(formatted)
                    st.session_state.session_lpp = lpp_data
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", human_response))
                    true_types = [key.replace("_", " ").title() for key, val in opt_types.items() if val]
                    if true_types:
                        st.session_state.history.append(("assistant", f"üìö **Detected Optimization Types:** `{', '.join(true_types)}`"))
                    else:
                        st.session_state.history.append(("assistant", "üìö **Detected Optimization Types:** `None detected`"))

        else:
            modified_lpp, error = modify_lpp(st.session_state.session_lpp, user_input)
            if error:
                st.session_state.history.append(("user", user_input))
                st.session_state.history.append(("assistant", f"‚ùå {error}"))
            else:
                err2, opt_val, opt_vars = solve_lpp(modified_lpp)
                if err2:
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", f"‚ùå {err2}"))
                else:
                    formatted = format_solution(opt_val, opt_vars, modified_lpp.get("objective"), modified_lpp)
                    human_response = humanize_response(formatted)
                    st.session_state.session_lpp = modified_lpp
                    st.session_state.history.append(("user", user_input))
                    st.session_state.history.append(("assistant", human_response))

# --- Chat Display ---
for sender, message in st.session_state.history:
    with st.chat_message(sender):
        st.markdown(message)
